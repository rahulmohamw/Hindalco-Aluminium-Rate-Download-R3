name: One-Time Bulk CSV Creation

on:
  workflow_dispatch:  # Manual trigger only

permissions:
  contents: write

jobs:
  bulk_extract_csv:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          
      - name: Install Dependencies
        run: |
          pip install PyPDF2
          
      - name: Run Bulk PDF to CSV Extraction
        run: |
          python3 - <<'EOF'
          import os
          import csv
          from datetime import datetime
          from PyPDF2 import PdfReader
          import glob
          
          CSV_DIR = "csv"
          
          def sanitize_filename(text):
              """Clean filename for CSV creation"""
              return text.replace("/", "-").replace("\"", "").replace(",", "").replace(":", "").replace(" ", "_").replace("%", "percent")
          
          def extract_date_from_filename(filename):
              """Extract date from filename patterns"""
              import re
              
              # Pattern: primary-ready-reckoner-11-july-2025.pdf
              match = re.search(r'(\d{1,2})-(\w+)-(\d{4})', filename.lower())
              if match:
                  day, month_name, year = match.groups()
                  month_mapping = {
                      'january': 1, 'jan': 1, 'february': 2, 'feb': 2, 'march': 3, 'mar': 3,
                      'april': 4, 'apr': 4, 'may': 5, 'june': 6, 'jun': 6, 'july': 7, 'jul': 7,
                      'august': 8, 'aug': 8, 'september': 9, 'sep': 9, 'october': 10, 'oct': 10,
                      'november': 11, 'nov': 11, 'december': 12, 'dec': 12
                  }
                  
                  month_num = month_mapping.get(month_name.lower())
                  if month_num:
                      try:
                          date_obj = datetime(int(year), month_num, int(day))
                          return date_obj.strftime("%Y-%m-%d")
                      except:
                          pass
              
              # Pattern: Hindalco_Circular_11_Jul_25.pdf
              match = re.search(r'(\d{1,2})_(\w+)_(\d{2})', filename)
              if match:
                  day, month_name, year = match.groups()
                  year_full = 2000 + int(year) if int(year) < 50 else 1900 + int(year)
                  
                  month_mapping = {
                      'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'may': 5, 'jun': 6,
                      'jul': 7, 'aug': 8, 'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12
                  }
                  
                  month_num = month_mapping.get(month_name.lower())
                  if month_num:
                      try:
                          date_obj = datetime(year_full, month_num, int(day))
                          return date_obj.strftime("%Y-%m-%d")
                      except:
                          pass
              
              return datetime.now().strftime("%Y-%m-%d")
          
          def extract_date_from_text(text):
              """Extract date from PDF text"""
              import re
              match = re.search(r'w\.e\.f\.\s*(\d{1,2}\.\d{1,2}\.\d{4})', text)
              if match:
                  try:
                      date_obj = datetime.strptime(match.group(1), "%d.%m.%Y")
                      return date_obj.strftime("%Y-%m-%d")
                  except:
                      pass
              return None
          
          def clean_description(desc):
              """Clean the description by removing unwanted patterns but preserving specifications"""
              import re
              desc = re.sub(r'\b\d{5,6}\b', '', desc)
              desc = re.sub(r'\b\d{4,}\b(?=\s|$)', '', desc)
              desc = ' '.join(desc.split())
              desc = desc.strip(' .-_')
              return desc
          
          def extract_table_data(pdf_path):
              """Extract data from PDF with duplicate prevention"""
              try:
                  reader = PdfReader(pdf_path)
                  text = "\n".join([page.extract_text() for page in reader.pages])
                  lines = text.splitlines()
                  
                  data_rows = []
                  seen_items = set()
                  current_date = extract_date_from_text(text)
                  if not current_date:
                      current_date = extract_date_from_filename(os.path.basename(pdf_path))
                  
                  print(f"   üìÖ Date: {current_date}")
                  
                  # Find table section
                  table_started = False
                  processed_numbers = set()
                  
                  for i, line in enumerate(lines):
                      line = line.strip()
                      
                      if "PRODUCTS" in line.upper() and "Basic Price" in line:
                          table_started = True
                          continue
                      
                      if table_started and any(stop_word in line.upper() for stop_word in ["NOTE", "QUANTITY DISCOUNT", "FREIGHT CHARGES", "TAXES"]):
                          break
                      
                      if table_started and line and len(line) > 2:
                          import re
                          number_match = re.match(r'^(\d+)\.\s+(.+)', line)
                          
                          if number_match:
                              item_number = number_match.group(1)
                              rest_of_line = number_match.group(2)
                              
                              if item_number in processed_numbers:
                                  continue
                              
                              processed_numbers.add(item_number)
                              parts = rest_of_line.split()
                              
                              if len(parts) >= 2:
                                  try:
                                      price_found = False
                                      for j in range(len(parts) - 1, -1, -1):
                                          try:
                                              price_str = parts[j].replace(",", "").replace("Rs/", "").replace("MT", "").strip()
                                              price_str = re.sub(r'[^\d]', '', price_str)
                                              
                                              if price_str:
                                                  price = int(price_str)
                                                  
                                                  if price > 100000:
                                                      desc_parts = parts[:j]
                                                      desc = " ".join(desc_parts)
                                                      desc = clean_description(desc)
                                                      
                                                      unique_key = f"{current_date}|{desc.lower()}"
                                                      
                                                      if len(desc) > 5 and unique_key not in seen_items:
                                                          seen_items.add(unique_key)
                                                          data_rows.append((current_date, desc, price))
                                                          price_found = True
                                                          print(f"   ‚úÖ Item {item_number}: {desc} ‚Üí ‚Çπ{price:,}")
                                                          break
                                          except (ValueError, IndexError):
                                              continue
                                      
                                      if not price_found and i + 1 < len(lines):
                                          next_line = lines[i + 1].strip()
                                          price_match = re.match(r'^(\d{6,})', next_line.replace(",", ""))
                                          if price_match:
                                              price = int(price_match.group(1))
                                              desc = " ".join(parts)
                                              desc = clean_description(desc)
                                              
                                              unique_key = f"{current_date}|{desc.lower()}"
                                              if len(desc) > 5 and unique_key not in seen_items:
                                                  seen_items.add(unique_key)
                                                  data_rows.append((current_date, desc, price))
                                                  print(f"   ‚úÖ Item {item_number} (next line): {desc} ‚Üí ‚Çπ{price:,}")
                                                  
                                  except Exception:
                                      continue
                  
                  print(f"   üìä Extracted {len(data_rows)} unique items")
                  return data_rows
                  
              except Exception as e:
                  print(f"   ‚ùå Error: {e}")
                  return []
          
          def create_csv_file(product_name, data_points):
              """Create CSV file for a product with duplicate removal"""
              filename = sanitize_filename(product_name) + ".csv"
              csv_path = os.path.join(CSV_DIR, filename)
              os.makedirs(CSV_DIR, exist_ok=True)
              
              # Remove duplicates based on date and price
              unique_data = {}
              for date, desc, price in data_points:
                  key = f"{date}|{price}"
                  if key not in unique_data:
                      unique_data[key] = (date, desc, price)
              
              final_data = list(unique_data.values())
              final_data.sort(key=lambda x: x[0])
              
              with open(csv_path, "w", newline="") as f:
                  writer = csv.writer(f)
                  writer.writerow(["Date", "Product", "Price"])
                  for date, desc, price in final_data:
                      writer.writerow([date, desc, price])
              
              print(f"   üíæ Created: {filename} ({len(final_data)} records)")
          
          # Main execution
          print("üöÄ Starting bulk extraction...")
          
          # Find all PDFs
          pdf_patterns = ["Downloads/**/*.pdf", "Downloads/**/**/*.pdf"]
          all_pdfs = []
          for pattern in pdf_patterns:
              all_pdfs.extend(glob.glob(pattern, recursive=True))
          
          hindalco_pdfs = []
          for pdf in all_pdfs:
              filename = os.path.basename(pdf).lower()
              if any(keyword in filename for keyword in ['hindalco', 'primary-ready-reckoner', 'circular']):
                  hindalco_pdfs.append(pdf)
          
          print(f"üîç Found {len(hindalco_pdfs)} PDF files")
          
          # Process PDFs
          product_data = {}
          for pdf_path in hindalco_pdfs:
              print(f"\nüîÑ Processing: {pdf_path}")
              extracted_rows = extract_table_data(pdf_path)
              
              for date, desc, price in extracted_rows:
                  if desc not in product_data:
                      product_data[desc] = []
                  product_data[desc].append((date, desc, price))
          
          # Create CSVs
          print(f"\nüìä Creating {len(product_data)} CSV files...")
          for product_name, data_points in product_data.items():
              create_csv_file(product_name, data_points)
          
          print(f"\n‚úÖ Completed! Created {len(product_data)} CSV files")
          EOF
          
      - name: Commit CSV Files
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          
          if ls csv/*.csv 1> /dev/null 2>&1; then
            git add csv/
            git commit -m "Initial bulk CSV creation from all historical PDFs [$(date '+%Y-%m-%d %H:%M:%S')]"
            git push
            echo "‚úÖ CSV files committed successfully"
          else
            echo "‚ùå No CSV files found to commit"
          fi
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
